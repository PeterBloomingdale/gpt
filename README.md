# OpenAI GPT API Functions

This repository contains a Python file (**gpt.py**) that enables users to call OpenAI's API for the large language models and generate responses to provided prompts.

The gpt.py file contains two functions **`gpt()`** and **`gpttxt()`**, which can be used to generate responses to a provided prompt or text file, respectively. The **`gpt()`** function takes a single string as input, and returns a string containing the generated response. The **`gpttxt()`** function takes a single string as input, which is the name of a text file, and returns a string containing the generated response.

## Getting Started

To get started with using these functions, you will first need to sign up for an OpenAI API key and Organization ID, which can be found on the [OpenAI Developer Dashboard](https://platform.openai.com/).

Next, create a file named **secrets.py** in the same directory as the **gpt.py** file, and define the following two variables:

```python
API_Key = 'your_api_key_here'
Organization_ID = 'your_organization_id_here'
```

Make sure to replace *your_api_key_here* and *your_organization_id_here* with your actual OpenAI API key and Organization ID, respectively.


## Usage

To use the functions, simply import either the **`gpt()`** or **`gpttxt()`** function from the **gpt.py** file and call the function with the required input parameters. 

For example, to use the **`gpt()`** function to generate a response to the prompt "What is the meaning of life?", you can use the following code:

```python
from gpt import gpt

gpt("What is the meaning of life?")
```

Similarly, to use the **`gpttxt()`** function to generate a response to the text in a file named input.txt, you can use the following code:

```python
from gpt import gpttxt

gpttxt('input.txt')
```

## OpenAI GPT API Models

The Python file uses the gpt-3.5-turbo model as the default model when making requests to the OpenAI GPT API.

A list of available models and additional details can be found [here](https://platform.openai.com/docs/models). 

The Python file can be easily modified to use any of these models by changing the value of the **model** variable in the **`gpt()`** and **`gpttxt()`** functions.

## API Settings

The Python file uses the following settings when making requests to the OpenAI GPT API:

* **temperature**: A value that controls the "creativity" or "randomness" of the generated text. A higher value will produce more varied and unpredictable responses, while a lower value will produce more predictable and conservative responses. The default value is 0.7, and the Python file sets it to 0.9.

* **max_tokens**: The maximum number of tokens (words and punctuation) to include in the generated text. The Python file sets it to 300, but the maximum value can go up to 4,096 (gpt-3.5-turbo). A good approach is to start with a small value and gradually increase it until the desired length of the generated text is achieved.

* **top_p**: A value that controls the "diversity" of the generated text by setting a threshold for the probability of each token. Tokens with a probability below this threshold are discarded, which encourages the API to generate less-common responses. The default value is 1.0, and the Python file sets it to 0.9.

* **n**: The number of responses to generate for each input prompt. The default value is 1, and the Python file sets it to 1.

Additional settings that could be included in API requests to the OpenAI GPT API to fine-tune the behavior and customize the generated responses for specific use cases include:

* **presence_penalty**: A value that discourages the API from repeating previous responses by penalizing tokens that have already been generated in the conversation. The default value is 0.0.

* **frequency_penalty**: A value that encourages the API to generate more varied responses by penalizing tokens that have already been used frequently in the conversation. The default value is 0.0.

* **stop**: A list of tokens that, when generated by the API, will indicate that the response is complete and the API should stop generating additional tokens. The default value is None.


## Disclaimer

Please note that the OpenAI GPT API is a powerful tool that can generate human-like responses to prompts, but it can also be easily abused to generate harmful or misleading content. Please use this tool responsibly and with caution.